{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Expectation-Maximization\n",
    "\n",
    "El algoritmo de Expectation-Maximization (EM) nos permite encontrar un máximo de la verosimilitud de los datos $X$, con respecto a los parametros $w$ de un modelo de la probabilidad conjunta $p(X, Z/w)$, donde $Z$ es una variable aleatoria latente, es decir, que no podemos medir pero suponemos que existe.\n",
    "\n",
    "(a) Derivar el algoritmo de EM para el caso de GMM, mostrando la función que resulta luego del E-step $(Q(w,w^o))$ y los valores óptimos $μ^∗_j, Σ^∗_j y π_j^∗$ que resultan luego del M-step.\n",
    "\n",
    "(b) Demostrar que la función resultante del E-step es una cota inferior de la log-likelihood $ln(p(X/w))$ y que para el caso de GMM esta es cóncava en los parámetros $μ_j, Σ_j y π_j$."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
